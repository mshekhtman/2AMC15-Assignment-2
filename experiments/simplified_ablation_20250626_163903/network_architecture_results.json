{
  "dqn": {
    "Tiny_Net": {
      "experiment_name": "dqn_Tiny_Net",
      "episode_rewards": [
        -1322.392857142851,
        -1227.3928571428485,
        -1420.4642857142712,
        -1461.357142857135,
        -1063.8571428571438,
        -651.9285714285732,
        -416.42857142857235,
        17.607142857142804,
        -939.2142857142862,
        -632.7857142857157,
        -1114.9642857142824,
        -531.6071428571445,
        -934.2857142857152,
        -452.3928571428596,
        -123.74999999999997,
        -1139.8214285714278,
        -1447.642857142851,
        -1363.464285714282,
        -565.3928571428576,
        -1202.7142857142833,
        -1597.7499999999902,
        -1493.0714285714191,
        -1193.749999999996,
        -746.3214285714284,
        -823.1071428571424
      ],
      "mean_reward": -953.9299999999972,
      "std_reward": 435.99613734948446,
      "success_rate": 0.64,
      "convergence_episode": 25,
      "final_10_avg": -1157.303571428568
    },
    "Small_Net": {
      "experiment_name": "dqn_Small_Net",
      "episode_rewards": [
        -1322.392857142851,
        -1227.3928571428485,
        -1420.4642857142712,
        -1461.357142857135,
        -1063.8571428571438,
        -1499.321428571422,
        -1338.0357142857097,
        -915.8928571428568,
        -811.1428571428564,
        -175.6071428571427,
        -512.2857142857148,
        -1763.7499999999907,
        -628.7857142857148,
        -1261.5357142857072,
        -899.750000000001,
        -190.42857142857142,
        -328.8928571428574,
        -1487.857142857135,
        -1499.4642857142787,
        -211.89285714285688,
        -89.92857142857142,
        -1474.8571428571365,
        -947.9999999999976,
        -104.8571428571428,
        -275.78571428571456
      ],
      "mean_reward": -916.5414285714251,
      "std_reward": 532.7354983402487,
      "success_rate": 0.64,
      "convergence_episode": 25,
      "final_10_avg": -661.1964285714264
    },
    "Medium_Net": {
      "experiment_name": "dqn_Medium_Net",
      "episode_rewards": [
        -1322.392857142851,
        -1227.3928571428485,
        -1420.4642857142712,
        -1461.357142857135,
        -1063.8571428571438,
        -911.2500000000014,
        -1311.321428571421,
        -507.8214285714304,
        -58.96428571428571,
        -1116.9642857142856,
        -1300.60714285714,
        -534.3928571428576,
        -1048.1785714285716,
        -1391.1071428571377,
        -1093.3214285714284,
        -1390.8214285714232,
        -1248.8571428571347,
        -554.178571428572,
        -1338.2142857142815,
        -1185.8571428571383,
        -1224.2499999999957,
        -1294.3928571428519,
        -1262.8928571428519,
        -1090.821428571427,
        -1001.5000000000016
      ],
      "mean_reward": -1094.4471428571394,
      "std_reward": 335.8839462051819,
      "success_rate": 0.48,
      "convergence_episode": 25,
      "final_10_avg": -1159.178571428568
    },
    "Large_Net": {
      "experiment_name": "dqn_Large_Net",
      "episode_rewards": [
        -1322.392857142851,
        -1227.3928571428485,
        -1420.4642857142712,
        -1461.357142857135,
        -1063.8571428571438,
        -394.03571428571587,
        -1277.1071428571315,
        -1464.6071428571374,
        -954.2499999999994,
        -865.9285714285718,
        -1216.0357142857104,
        -530.5714285714301,
        -1249.1428571428512,
        -338.6785714285718,
        -1406.571428571424,
        -696.9642857142858,
        -1441.8571428571365,
        -147.7142857142857,
        -746.4642857142865,
        -459.6071428571452,
        -478.21428571428646,
        -995.4285714285725,
        -1176.1071428571386,
        -1312.785714285709,
        -760.5
      ],
      "mean_reward": -976.3214285714255,
      "std_reward": 398.7612123687473,
      "success_rate": 0.68,
      "convergence_episode": 25,
      "final_10_avg": -821.5642857142846
    },
    "Deep_Net": {
      "experiment_name": "dqn_Deep_Net",
      "episode_rewards": [
        -1322.392857142851,
        -1227.3928571428485,
        -1420.4642857142712,
        -1461.357142857135,
        -1063.8571428571438,
        -1338.8928571428485,
        -1488.999999999993,
        -1233.0714285714232,
        -1208.107142857138,
        -1097.6428571428505,
        -1228.6071428571374,
        -1073.3214285714278,
        -203.32142857142802,
        -1331.6428571428546,
        -437.5714285714287,
        -618.2500000000014,
        -162.60714285714275,
        -339.1071428571455,
        -400.82142857143043,
        -1337.8214285714243,
        -263.67857142857196,
        -1023.4642857142853,
        -367.3928571428585,
        -332.4642857142862,
        -1162.9642857142799
      ],
      "mean_reward": -925.8085714285683,
      "std_reward": 454.46608210478195,
      "success_rate": 0.64,
      "convergence_episode": 25,
      "final_10_avg": -600.8571428571427
    }
  },
  "ppo": {
    "Tiny_Net": {
      "experiment_name": "ppo_Tiny_Net",
      "episode_rewards": [
        -652.3214285714286,
        -1439.821428571423,
        -1672.4642857142746,
        -1544.2142857142771,
        -1834.357142857128,
        -1441.5714285714214,
        -811.1428571428581,
        -1789.8214285714205,
        -1478.7142857142794,
        -1309.9285714285677,
        -1486.4642857142733,
        -1086.7857142857144,
        -1462.9642857142774,
        -706.1428571428581,
        -1649.4642857142705,
        -1615.1071428571295,
        -203.82142857142847,
        -985.7142857142845,
        -1466.2142857142728,
        -1441.6071428571322,
        -839.4999999999995,
        -1518.035714285707,
        -1598.7857142857035,
        -1659.1071428571363,
        -1329.2142857142815
      ],
      "mean_reward": -1320.931428571422,
      "std_reward": 397.5221277270608,
      "success_rate": 0.32,
      "convergence_episode": 25,
      "final_10_avg": -1265.7107142857074
    },
    "Small_Net": {
      "experiment_name": "ppo_Small_Net",
      "episode_rewards": [
        -1868.4642857142796,
        -2170.0000000000045,
        -604.8571428571433,
        -1301.5714285714218,
        -818.8571428571425,
        -1279.357142857137,
        -1208.3928571428544,
        -1173.4285714285659,
        -1347.1428571428478,
        -1260.2499999999964,
        -1346.3928571428505,
        -348.21428571428606,
        -699.4642857142868,
        -1165.2142857142783,
        -1111.1071428571381,
        -1240.7142857142833,
        -1160.821428571427,
        -1312.892857142854,
        -1159.107142857139,
        -1630.9285714285554,
        -778.7142857142861,
        -567.678571428573,
        -1010.2857142857135,
        -1275.1785714285681,
        -1171.107142857141
      ],
      "mean_reward": -1160.405714285711,
      "std_reward": 385.7670584110323,
      "success_rate": 0.44,
      "convergence_episode": 11,
      "final_10_avg": -1130.742857142854
    },
    "Medium_Net": {
      "experiment_name": "ppo_Medium_Net",
      "episode_rewards": [
        -975.2499999999994,
        -1926.3214285714203,
        -1786.8214285714112,
        -1089.5714285714278,
        -1550.785714285701,
        -628.1071428571443,
        -951.0000000000005,
        -598.2142857142874,
        -1360.535714285709,
        -776.4642857142869,
        -1231.8214285714218,
        -1619.6071428571345,
        -1340.571428571419,
        -676.1428571428573,
        -1456.3928571428519,
        -1867.249999999993,
        -991.1071428571429,
        -1130.7142857142842,
        -991.3571428571428,
        -737.1785714285718,
        -1438.1071428571322,
        -1005.7142857142849,
        -1442.392857142848,
        -1352.8571428571333,
        -934.0714285714289
      ],
      "mean_reward": -1194.3342857142814,
      "std_reward": 376.7705461916412,
      "success_rate": 0.52,
      "convergence_episode": 25,
      "final_10_avg": -1189.0749999999964
    },
    "Large_Net": {
      "experiment_name": "ppo_Large_Net",
      "episode_rewards": [
        -1609.1071428571306,
        -688.4642857142874,
        -1113.75,
        -1366.499999999993,
        -1196.821428571423,
        -919.6428571428573,
        -1265.7142857142792,
        -1324.5357142857047,
        -1588.8214285714205,
        -1480.8928571428487,
        -324.8928571428572,
        -171.82142857142813,
        -1381.3214285714225,
        -800.8571428571423,
        -861.2500000000014,
        -763.3928571428588,
        -730.2857142857147,
        -1330.9999999999964,
        -1452.285714285703,
        -693.8928571428576,
        -806.0357142857163,
        -1083.642857142856,
        -1502.2857142857113,
        -1720.8928571428453,
        -505.64285714286063
      ],
      "mean_reward": -1067.3499999999967,
      "std_reward": 412.0447596798054,
      "success_rate": 0.6,
      "convergence_episode": 25,
      "final_10_avg": -1058.935714285712
    },
    "Deep_Net": {
      "experiment_name": "ppo_Deep_Net",
      "episode_rewards": [
        -1688.1428571428505,
        -1618.857142857133,
        -1817.4999999999882,
        -1502.5357142857076,
        -1365.3928571428505,
        -977.9642857142871,
        -1546.2142857142735,
        -479.28571428571456,
        -875.1785714285721,
        -1448.0714285714223,
        -1325.0714285714198,
        -1280.8571428571358,
        -1094.9999999999982,
        -440.96428571428737,
        -259.53571428571416,
        -419.214285714287,
        -1272.142857142851,
        -1220.0357142857129,
        -890.0357142857148,
        -1344.8928571428523,
        -1438.6785714285656,
        -1823.7857142857047,
        -1002.8571428571427,
        -1500.392857142854,
        -622.8571428571437
      ],
      "mean_reward": -1170.2185714285674,
      "std_reward": 441.89461636393054,
      "success_rate": 0.48,
      "convergence_episode": 25,
      "final_10_avg": -1153.4892857142827
    }
  }
}